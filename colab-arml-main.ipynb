{"nbformat":4,"nbformat_minor":5,"metadata":{"accelerator":"GPU","colab":{"name":"colab-arml-main.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"interpreter":{"hash":"0fd9392274fc82a63c2a75f43f796d95e051853c3a46ffe4696bb4291dc65e3b"},"kernelspec":{"display_name":"Python 3.8.11 64-bit ('base': conda)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.11"}},"cells":[{"cell_type":"markdown","metadata":{"id":"0jJG06bS16dE"},"source":["# Google Colab Main Document \n","\n","This notebook is the main runs the main experiments for adverasrial attacks against the [RadioML](https://www.deepsig.ai/datasets) dataset. It is recommended that a GPU is used to run the code to reduce the amount of time it takes to generate the results. \n","\n","The environment requires the [Adversarial Robustness Toolbox](https://github.com/Trusted-AI/adversarial-robustness-toolbox) which is installed in this document. If you're running this code on a cloud node or a personal machine then you need to make sure this package is installed along with the other dependencies. One other note to take into account is that this notebook is only designed to run on Google Colab because it connects to my Google Drive. \n"],"id":"0jJG06bS16dE"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BAxqNThB1ymJ","executionInfo":{"elapsed":19412,"status":"ok","timestamp":1631547130432,"user":{"displayName":"Gregory Ditzler","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggn0J_LkmcMscpWX4MrIjo_GWcI9inmoVYX5R-7gm4=s64","userId":"15695354258891211130"},"user_tz":420},"outputId":"90ac8bf7-0d5f-46dc-c3cf-e33815a5ae2b"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive') "],"id":"BAxqNThB1ymJ","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oKjF9P6k2DL7","executionInfo":{"elapsed":908,"status":"ok","timestamp":1631547131333,"user":{"displayName":"Gregory Ditzler","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggn0J_LkmcMscpWX4MrIjo_GWcI9inmoVYX5R-7gm4=s64","userId":"15695354258891211130"},"user_tz":420},"outputId":"e9ed9061-0220-4e88-997f-8cec4d165218"},"source":["%cd /content/gdrive/MyDrive/Git/adversarial-radioml/"],"id":"oKjF9P6k2DL7","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["/content/gdrive/MyDrive/Git/adversarial-radioml\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WhwQ-u342M79","executionInfo":{"elapsed":13604,"status":"ok","timestamp":1631547146705,"user":{"displayName":"Gregory Ditzler","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggn0J_LkmcMscpWX4MrIjo_GWcI9inmoVYX5R-7gm4=s64","userId":"15695354258891211130"},"user_tz":420},"outputId":"d9b17a3b-191b-40e4-db70-cb5d586d58d6"},"source":["!pip install -r requirements.txt"],"id":"WhwQ-u342M79","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting adversarial-robustness-toolbox\n","  Downloading adversarial_robustness_toolbox-1.7.2-py3-none-any.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 12.7 MB/s \n","\u001b[?25hCollecting numba~=0.53.1\n","  Downloading numba-0.53.1-cp37-cp37m-manylinux2014_x86_64.whl (3.4 MB)\n","\u001b[K     |████████████████████████████████| 3.4 MB 41.5 MB/s \n","\u001b[?25hRequirement already satisfied: scikit-learn<0.24.3,>=0.22.2 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox->-r requirements.txt (line 1)) (0.22.2.post1)\n","Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox->-r requirements.txt (line 1)) (1.19.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox->-r requirements.txt (line 1)) (57.4.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox->-r requirements.txt (line 1)) (4.62.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox->-r requirements.txt (line 1)) (1.4.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox->-r requirements.txt (line 1)) (1.15.0)\n","Collecting llvmlite<0.37,>=0.36.0rc1\n","  Downloading llvmlite-0.36.0-cp37-cp37m-manylinux2010_x86_64.whl (25.3 MB)\n","\u001b[K     |████████████████████████████████| 25.3 MB 1.4 MB/s \n","\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.24.3,>=0.22.2->adversarial-robustness-toolbox->-r requirements.txt (line 1)) (1.0.1)\n","Installing collected packages: llvmlite, numba, adversarial-robustness-toolbox\n","  Attempting uninstall: llvmlite\n","    Found existing installation: llvmlite 0.34.0\n","    Uninstalling llvmlite-0.34.0:\n","      Successfully uninstalled llvmlite-0.34.0\n","  Attempting uninstall: numba\n","    Found existing installation: numba 0.51.2\n","    Uninstalling numba-0.51.2:\n","      Successfully uninstalled numba-0.51.2\n","Successfully installed adversarial-robustness-toolbox-1.7.2 llvmlite-0.36.0 numba-0.53.1\n"]}]},{"cell_type":"markdown","metadata":{"id":"S4i37i1V2W02"},"source":["# Experiments \n","\n","- `test_exp_fgsm.py`: This script runs an experiment that evaluates different values of epsilon in the Fast Gradient Sign Method attack. The values for epsilon are `[0.01, 0.025, 0.5, ..., 0.2]`. The output is saved in a pickle file in `outputs/`\n","- `test_exp_multiple_attacks.py`: This script runs an experiment that generated adversarial data using FGSM, PGD and DeepFool. The output is saved in a pickle file in `outputs/`. This script is very time consuming and it is recommended that a TPU is used to accelerate the training time. "],"id":"S4i37i1V2W02"},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"ukNlHMJz2RVC"},"source":["!python test_exp_fgsm.py"],"id":"ukNlHMJz2RVC","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"8DEAqr-m2Y7r"},"source":["!python test_exp_single_attack.py FastGradientMethod"],"id":"8DEAqr-m2Y7r","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"CHCK6_-C-HCG"},"source":["!python test_exp_single_attack.py DeepFool"],"id":"CHCK6_-C-HCG","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oZUgcb8jUGzA"},"source":["!python test_exp_single_attack.py ProjectedGradientDescent"],"id":"oZUgcb8jUGzA","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rb6hQ6_ZdeuY","executionInfo":{"elapsed":635,"status":"ok","timestamp":1631547150766,"user":{"displayName":"Gregory Ditzler","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggn0J_LkmcMscpWX4MrIjo_GWcI9inmoVYX5R-7gm4=s64","userId":"15695354258891211130"},"user_tz":420},"outputId":"0ac5da6b-cd02-4b84-b586-7ec21a21b013"},"source":["!ls outputs"],"id":"rb6hQ6_ZdeuY","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["aml_fgsm_vtcnn2_vtcnn2_scenario_A_radioml.pkl\n","aml_radioml_vtcnn2_vtcnn2_scenario_A_single_attack_DeepFool.pkl\n","aml_radioml_vtcnn2_vtcnn2_scenario_A_single_attack_FastGradientMethod.pkl\n","aml_vtcnn2_vtcnn2_scenario_A_radioml.pkl\n","radioml_adversarial_accuracy.pdf\n","radioml_adversarial_auc.pdf\n","radioml_adversarial_perplexity.pdf\n","radioml_fgsm_accuracy_epsilons.pdf\n","radioml_fgsm_auc_epsilons.pdf\n","README.md\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QLFsOXI6G57u","executionInfo":{"elapsed":7022,"status":"ok","timestamp":1631547202933,"user":{"displayName":"Gregory Ditzler","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggn0J_LkmcMscpWX4MrIjo_GWcI9inmoVYX5R-7gm4=s64","userId":"15695354258891211130"},"user_tz":420},"outputId":"f3415bbe-903e-4d76-9eb7-22a285746573"},"source":["import pickle \n","pickle.load(open('outputs/aml_fgsm_vtcnn2_vtcnn2_scenario_A_radioml.pkl', 'rb'))['result_logger'].count"],"id":"QLFsOXI6G57u","execution_count":null,"outputs":[{"data":{"text/plain":["5"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2xFdxEp7HNQ7","executionInfo":{"elapsed":13844,"status":"ok","timestamp":1631547227800,"user":{"displayName":"Gregory Ditzler","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggn0J_LkmcMscpWX4MrIjo_GWcI9inmoVYX5R-7gm4=s64","userId":"15695354258891211130"},"user_tz":420},"outputId":"17b661ec-4594-4ae4-c5f5-d9d6330d7ef6"},"source":["!git status"],"id":"2xFdxEp7HNQ7","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","Changes not staged for commit:\n","  (use \"git add <file>...\" to update what will be committed)\n","  (use \"git checkout -- <file>...\" to discard changes in working directory)\n","\n","\t\u001b[31mmodified:   Results.ipynb\u001b[m\n","\t\u001b[31mmodified:   colab-arml-main.ipynb\u001b[m\n","\t\u001b[31mmodified:   test_exp_fgsm.py\u001b[m\n","\t\u001b[31mmodified:   test_exp_multiple_attacks.py\u001b[m\n","\n","Untracked files:\n","  (use \"git add <file>...\" to include in what will be committed)\n","\n","\t\u001b[31moutputs/aml_fgsm_vtcnn2_vtcnn2_scenario_A_radioml.pkl\u001b[m\n","\t\u001b[31moutputs/aml_radioml_vtcnn2_vtcnn2_scenario_A_single_attack_DeepFool.pkl\u001b[m\n","\n","no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GIJKqm2qyseJ","executionInfo":{"elapsed":9,"status":"ok","timestamp":1631547245571,"user":{"displayName":"Gregory Ditzler","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggn0J_LkmcMscpWX4MrIjo_GWcI9inmoVYX5R-7gm4=s64","userId":"15695354258891211130"},"user_tz":420},"outputId":"a7d1b076-f7cb-4f1d-b3d7-6c9920fdbd38"},"source":["!ls -lah outputs"],"id":"GIJKqm2qyseJ","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["total 91K\n","-rw------- 1 root root 3.8K Sep 13 12:04 aml_fgsm_vtcnn2_vtcnn2_scenario_A_radioml.pkl\n","-rw------- 1 root root 4.0K Sep 13 03:02 aml_radioml_vtcnn2_vtcnn2_scenario_A_single_attack_DeepFool.pkl\n","-rw------- 1 root root 4.0K Sep 12 01:59 aml_radioml_vtcnn2_vtcnn2_scenario_A_single_attack_FastGradientMethod.pkl\n","-rw------- 1 root root 3.7K Sep  9 16:51 aml_vtcnn2_vtcnn2_scenario_A_radioml.pkl\n","-rw------- 1 root root  17K Sep 10 19:35 radioml_adversarial_accuracy.pdf\n","-rw------- 1 root root  16K Sep 10 19:35 radioml_adversarial_auc.pdf\n","-rw------- 1 root root  16K Sep 10 19:35 radioml_adversarial_perplexity.pdf\n","-rw------- 1 root root  14K Sep 10 17:25 radioml_fgsm_accuracy_epsilons.pdf\n","-rw------- 1 root root  13K Sep 10 17:25 radioml_fgsm_auc_epsilons.pdf\n","-rw------- 1 root root  318 Sep 12 02:03 README.md\n"]}]},{"cell_type":"code","metadata":{"id":"BrXUw-m1yzEx"},"source":[""],"id":"BrXUw-m1yzEx","execution_count":null,"outputs":[]}]}